Training Start!
2018-12-02 07:36:12.680921: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.05GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-02 07:36:12.681017: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.57GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-02 07:36:12.826899: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.20GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-02 07:36:12.980631: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.57GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-02 07:36:12.980690: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.30GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-02 07:36:13.044831: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.42GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-02 07:36:13.123667: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
Epoch: 0001 Train Acc.= 0.17
Epoch: 0002 Train Acc.= 0.126
Epoch: 0003 Train Acc.= 0.208
Epoch: 0004 Train Acc.= 0.096
Epoch: 0005 Train Acc.= 0.206
Epoch: 0006 Train Acc.= 0.146
Epoch: 0007 Train Acc.= 0.292
Epoch: 0008 Train Acc.= 0.41
Epoch: 0009 Train Acc.= 0.608
Epoch: 0010 Train Acc.= 0.724
Epoch: 0011 Train Acc.= 0.71
Epoch: 0012 Train Acc.= 0.722
Epoch: 0013 Train Acc.= 0.648
Epoch: 0014 Train Acc.= 0.932
Epoch: 0015 Train Acc.= 0.956
Epoch: 0016 Train Acc.= 0.942
Epoch: 0017 Train Acc.= 0.926
Epoch: 0018 Train Acc.= 0.982
Training Done!
2018-12-02 07:39:50.672476: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.01GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-02 07:39:50.707158: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.20GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-02 07:39:50.707209: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
Test Acc.= 74.50729852318764

Process finished with exit code 0
