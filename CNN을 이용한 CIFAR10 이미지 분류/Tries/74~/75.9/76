Training Start!
2018-12-02 16:02:12.445453: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.05GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-02 16:02:12.445555: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.57GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-02 16:02:12.590021: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.20GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-02 16:02:12.743810: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.57GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-02 16:02:12.743845: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.30GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-02 16:02:12.807664: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.42GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-02 16:02:12.885645: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
Epoch: 0001 Train Acc.= 0.116
Epoch: 0002 Train Acc.= 0.114
Epoch: 0003 Train Acc.= 0.134
Epoch: 0004 Train Acc.= 0.166
Epoch: 0005 Train Acc.= 0.222
Epoch: 0006 Train Acc.= 0.192
Epoch: 0007 Train Acc.= 0.228
Epoch: 0008 Train Acc.= 0.32
Epoch: 0009 Train Acc.= 0.394
Epoch: 0010 Train Acc.= 0.46
Epoch: 0011 Train Acc.= 0.63
Epoch: 0012 Train Acc.= 0.736
Epoch: 0013 Train Acc.= 0.706
Epoch: 0014 Train Acc.= 0.808
Epoch: 0015 Train Acc.= 0.786
Epoch: 0016 Train Acc.= 0.92
Epoch: 0017 Train Acc.= 0.972
Training Done!
2018-12-02 16:05:34.021133: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.01GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-02 16:05:34.054521: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.20GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-02 16:05:34.054572: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
Test Acc.= 75.98109817504883

Process finished with exit code 0