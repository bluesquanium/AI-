ssh://bob@115.145.188.73:10022/etc/anaconda3/bin/python -u /home/bob/AIproject/hw_cnn.py
/etc/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
2018-12-03 11:18:04.163376: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2018-12-03 11:18:06.765019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:18:00.0
totalMemory: 11.91GiB freeMemory: 11.75GiB
2018-12-03 11:18:06.765086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-12-03 11:18:07.062756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-03 11:18:07.062813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-12-03 11:18:07.062823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-12-03 11:18:07.063090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2317 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
2018-12-03 11:18:10.869055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-12-03 11:18:10.869159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-03 11:18:10.869173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-12-03 11:18:10.869201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-12-03 11:18:10.869475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2317 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
Training Start!
Epoch: 0001 Train Acc.= 0.105
Epoch: 0002 Train Acc.= 0.155
Epoch: 0003 Train Acc.= 0.27
Epoch: 0004 Train Acc.= 0.4
Epoch: 0005 Train Acc.= 0.61
Epoch: 0006 Train Acc.= 0.66
Epoch: 0007 Train Acc.= 0.69
Epoch: 0008 Train Acc.= 0.75
Epoch: 0009 Train Acc.= 0.76
Epoch: 0010 Train Acc.= 0.89
Epoch: 0011 Train Acc.= 0.865
Epoch: 0012 Train Acc.= 0.92
Epoch: 0013 Train Acc.= 0.92
Epoch: 0014 Train Acc.= 0.91
Epoch: 0015 Train Acc.= 0.955
Epoch: 0016 Train Acc.= 0.93
Epoch: 0017 Train Acc.= 0.95
Epoch: 0018 Train Acc.= 0.865
Epoch: 0019 Train Acc.= 0.935
Epoch: 0020 Train Acc.= 0.845
Epoch: 0021 Train Acc.= 0.925
Epoch: 0022 Train Acc.= 0.99
Epoch: 0023 Train Acc.= 0.955
Training Done!
2018-12-03 11:23:16.568585: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.01GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-03 11:23:16.603463: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.20GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-03 11:23:16.603542: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-03 11:23:16.700278: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.08GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-03 11:23:16.902114: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.61GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-12-03 11:23:16.902158: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.34GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
Test Acc.= 80.07329915165901

Process finished with exit code 0
